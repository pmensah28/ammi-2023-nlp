{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# MMI_2024_NLP - Week 1\n",
        "\n",
        "#Lab 1: Part 1 - Naive Bayes"
      ],
      "metadata": {
        "id": "AW1aaO3bvcbJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "\n",
        "Before we start, please change the name of the notebook to the following format : **Firstname_LASTNAME_Lab1_A_naive_bayes.ipynb**\n",
        "\n",
        "\n",
        "In some cells and files you will see code blocks that look like this:\n",
        "\n",
        "```python\n",
        "##############################################################################\n",
        "#                    TODO: Write the equation for a line                     #\n",
        "##############################################################################\n",
        "pass\n",
        "##############################################################################\n",
        "#                              END OF YOUR CODE                              #\n",
        "##############################################################################\n",
        "```\n",
        "\n",
        "You should replace the `pass` statement with your own code and leave the blocks intact, like this:\n",
        "\n",
        "```python\n",
        "##############################################################################\n",
        "#                    TODO: Write the equation for a line                     #\n",
        "##############################################################################\n",
        "y = m * x + b\n",
        "##############################################################################\n",
        "#                              END OF YOUR CODE                              #\n",
        "##############################################################################\n",
        "```"
      ],
      "metadata": {
        "id": "ZTy7S86Kn1ze"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (A) Naive Bayes model"
      ],
      "metadata": {
        "id": "5kQJhsHhn4hb"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRqye55SXDsa"
      },
      "source": [
        "In this lab, we will implement a language identifier (LID).\n",
        "\n",
        "Our first model will be based on Naive Bayes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jlo96veyXDsb"
      },
      "outputs": [],
      "source": [
        "import io, sys, math, re\n",
        "from collections import defaultdict\n",
        "from typing import List, Tuple, Dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UdfI-OmXDsc"
      },
      "source": [
        "The next function is used to load the data. Each line of the data consist of a label (corresponding to a language), followed by some text, written in that language. Here is an example of data:\n",
        "\n",
        "```__label__de Zur Namensdeutung gibt es mehrere Varianten.```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "CjHGIo9gXDsc"
      },
      "outputs": [],
      "source": [
        "def load_data(filename:str)->List[Tuple]:\n",
        "    fin = io.open(filename, 'r', encoding='utf-8')\n",
        "    data = []\n",
        "    for line in fin:\n",
        "        tokens = line.split()\n",
        "        # print(len(tokens))\n",
        "        data.append((tokens[0], tokens[1:]))\n",
        "    return data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cY1bqzizXDsd"
      },
      "source": [
        "You can now try loading the first dataset `train1.txt` and look what examples look like."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "dtlY6M6tXDsd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a383b899-fae1-494b-bf3b-0bac6f9c0e8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('__label__de', ['Ich', 'würde', 'alles', 'tun,', 'um', 'dich', 'zu', 'beschützen.'])\n"
          ]
        }
      ],
      "source": [
        "data = load_data(\"/content/drive/MyDrive/AMMI-23/nlp/Lab1/train1.txt\")\n",
        "print(data[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BuXwK6eRXDsd"
      },
      "source": [
        "Next, we will start implementing the Naive Bayes method. This technique is based on word counts, and we thus need to start by implementing a function to count the words and labels of our training set.\n",
        "\n",
        "`n_examples` is the total number of examples\n",
        "\n",
        "`n_words_per_label` is the total number of words for a given label\n",
        "\n",
        "`label_counts` is the number of times a given label appears in the training data\n",
        "\n",
        "`word_counts` is the number of times a word appears with a given label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "_O6QtghUXDsd"
      },
      "outputs": [],
      "source": [
        "def count_words(data:str)->Dict:\n",
        "    n_examples = 0\n",
        "    n_words_per_label = defaultdict(lambda: 0)\n",
        "    label_counts = defaultdict(lambda: 0)\n",
        "    word_counts = defaultdict(lambda: defaultdict(lambda: 0.0))\n",
        "\n",
        "    for example in data:\n",
        "        label, sentence = example\n",
        "        ##########################################################################\n",
        "        #                      TODO: Implement this function                     #\n",
        "        ##########################################################################\n",
        "        # Replace \"pass\" statement with your code\n",
        "        n_examples += 1\n",
        "        label_counts[label] += 1\n",
        "        n_words_per_label[label] += len(sentence)\n",
        "\n",
        "        for word in sentence:\n",
        "          word_counts[label][word] += 1\n",
        "        ##########################################################################\n",
        "        #                            END OF YOUR CODE                            #\n",
        "        ##########################################################################\n",
        "\n",
        "    return {'label_counts': label_counts,\n",
        "            'word_counts': word_counts,\n",
        "            'n_examples': n_examples,\n",
        "            'n_words_per_label': n_words_per_label}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5BBqz2JXDse"
      },
      "source": [
        "Next, using the word and label counts from the previous function, we can implement the prediction function.\n",
        "\n",
        "Here, `mu` is a regularization parameter (Laplace smoothing), and `sentence` is the list of words corresponding to the test example."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "counts = count_words(data)\n",
        "counts"
      ],
      "metadata": {
        "id": "vCpGhA23v4T_"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "46_dbxuDXDse"
      },
      "outputs": [],
      "source": [
        "def predict(sentence:List, mu:float, label_counts:Dict, word_counts:Dict, n_examples:int, n_words_per_label:Dict)->str:\n",
        "    best_label = None\n",
        "    best_score = float('-inf')\n",
        "\n",
        "    for label in word_counts.keys():\n",
        "        score = 0.0\n",
        "        prior = label_counts[label] / sum(label_counts.values())\n",
        "        #P(Class | Word) = P(Class) * P(word | Class)\n",
        "        ##########################################################################\n",
        "        #                      TODO: Implement this function                     #\n",
        "        ##########################################################################\n",
        "        # Replace \"pass\" statement with your code\n",
        "        score += math.log(prior)\n",
        "\n",
        "        for word in sentence:\n",
        "          word_count = word_counts[label][word]\n",
        "          total_words = n_words_per_label[label]\n",
        "          vocab_size = len(word_counts[label])\n",
        "\n",
        "          word_probability = (word_count + mu) / (total_words + mu * vocab_size)\n",
        "          score += math.log(word_probability)\n",
        "\n",
        "        if score > best_score:\n",
        "          best_score = score\n",
        "          best_label = label\n",
        "        ##########################################################################\n",
        "        #                            END OF YOUR CODE                            #\n",
        "        ##########################################################################\n",
        "\n",
        "    return best_label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGMlrhFmXDsf"
      },
      "source": [
        "The next function will be used to evaluate the Naive Bayes model on a validation set. It computes the accuracy for a particular regularization parameter `mu`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "QE0EVY6OXDsf"
      },
      "outputs": [],
      "source": [
        "def compute_accuracy(valid_data:str, mu:float, counts:Dict)->float:\n",
        "    accuracy = 0.0\n",
        "    for label, sentence in valid_data:\n",
        "      ##########################################################################\n",
        "      #                      TODO: Implement this function                     #\n",
        "      ##########################################################################\n",
        "      # Replace \"pass\" statement with your code\n",
        "      predicted_label = predict(sentence, mu, counts['label_counts'], counts['word_counts'], counts['n_examples'], counts['n_words_per_label'])\n",
        "      if predicted_label == label:\n",
        "        accuracy += 1\n",
        "\n",
        "      acc = accuracy / len(valid_data)\n",
        "      ##########################################################################\n",
        "      #                            END OF YOUR CODE                            #\n",
        "      ##########################################################################\n",
        "\n",
        "    return acc # Replace \"...\" statement with your code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "l0NY2-oSXDsf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f82b3673-d145-4e28-ad89-6bc78a4ebcd1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "** Naive Bayes on train1.txt and valid1.txt **\n",
            "\n",
            "Validation accuracy: 0.941\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"\")\n",
        "print(\"** Naive Bayes on train1.txt and valid1.txt **\")\n",
        "print(\"\")\n",
        "\n",
        "mu = 1.0\n",
        "train_data = load_data(\"/content/drive/MyDrive/AMMI-23/nlp/Lab1/train1.txt\")\n",
        "valid_data = load_data(\"/content/drive/MyDrive/AMMI-23/nlp/Lab1/valid1.txt\")\n",
        "counts = count_words(train_data)\n",
        "\n",
        "print(\"Validation accuracy: %.3f\" % compute_accuracy(valid_data, mu, counts))\n",
        "print(\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Now, it is your turn, try to do it with train2.txt and valid2.txt.\n"
      ],
      "metadata": {
        "id": "1pYhDzXRuMIw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\")\n",
        "print(\"** Naive Bayes on train2.txt and valid2.txt**\")\n",
        "print(\"\")\n",
        "\n",
        "mu = 1.0\n",
        "train_data = load_data(\"/content/drive/MyDrive/AMMI-23/nlp/Lab1/train2.txt\")\n",
        "valid_data = load_data(\"/content/drive/MyDrive/AMMI-23/nlp/Lab1/valid2.txt\")\n",
        "counts = count_words(train_data)\n",
        "\n",
        "print(\"Validation accuracy: %.3f\" % compute_accuracy(valid_data, mu, counts))\n",
        "print(\"\")"
      ],
      "metadata": {
        "id": "wdb6zb9guY01",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3dc886d1-0399-4983-fced-e79f18367e39"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "** Naive Bayes on train2.txt and valid2.txt**\n",
            "\n",
            "Validation accuracy: 0.980\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Gg69xhqh8DPr"
      },
      "execution_count": 9,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.2+"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}